# 面试

## 计算机网络

### TCP

**TCP 报文头结构：**

| 源端口号 | 目标端口号 | 序列号 | 确认应答号 | 首部长度 | 保留位 | 控制位 | 窗口大小 | 校验和 | 紧急指针 | 选项 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 16 | 16 | 32 | 32 | 4 | 6 | 6 | 16 | 16 | 16 | 可变 |

- 序列号，建立连接时生成随机数为初始值，通过 SYN 发送给接收主机，没发送一次累加一次，解决乱序问题。
- 确认应答号，下次期望收到数据的序列号，发送到收到确认应答可以认为主机正常接收，解决丢包问题。
- 控制位
  - URG，紧急标志位，表示此报文为紧急数据，排在普通报文前面，接收端收到此报文后必须先处理紧急数据
  - ACK，确认应答，TCP 规定除了最初建立连接时的 SYN 包之外都必须为 1
  - PSH，催促标志位，TCP 立即生成一个报文发送给接收端，接收端收到后立即将缓冲区内的数据交付给应用程序，而不是等待缓冲区满。
  - RST，TCP 连接中出现异常必须断开连接
  - SYN，希望建立连接，并在序列号字段设定初始值
  - FIN，表示是否还会有数据发送，希望断开连接
- 窗口大小，TCP 流量控制，告诉对方本端缓冲区还能容纳多少数据，对方可以控制发送数据的速度。
- 校验和，执行 CRC 算法检验 TCP 报文是否在传输过程中收到破坏
- 紧急指针，偏移量，与序列号进行相加表示最后一个紧急数据的下一个字节的序列号

**TCP 的三次握手？**

1. 服务端监听固定端口，状态 LISTEN
2. 客户端发送第一次握手报文，控制位 SYN，seq=x，状态为 SYN_SEND
3. 服务端收到客户端发送的第一次握手报文，状态变为 SYN_RCVD
4. 服务端发送第二次握手报文，控制位 SYN ACK，ack=x+1，seq=y
5. 客户端收到服务端发送的第二次握手报文，状态修改为 ESTABLISHED
6. 客户端发送第三次握手报文，控制位 ACK=y+1
7. 服务端接收到客户端的第三次握手报文，状态修改为 ESTABLISHED

**为什么是三次，不是两次或四次？**

两次无法保证双端状态
四次浪费网络资源

**TCP 四次挥手？**

1. 客户端状态 FIN_WAIT_1，客户端发送第一次挥手报文，控制位 FIN ACK，seq=x+1，ack=y+1
2. 服务端收到客户端第一次挥手报文，状态变为 CLOSE_WAIT
3. 服务端发送第二次挥手，控制位 ACK，ack=x+1+1
4. 服务端发送第三次挥手，控制位 FIN，seq=y+1，状态变为 LAST_ACK
5. 客户端接收服务端第三次挥手，状态变为 FIN_WAIT_2
6. 客户端发送第四次挥手，控制位 ACK，ack=y+1+1，状态变为 TIME_WAIT
7. 服务端接收到客户端第四次挥手，状态变为 CLOSE
8. 客户端在 2MSL 后，状态变更为 CLOSE

**为什么是四次，不是3次？**

> 服务端在接收到第一次挥手后，需要处理完客户端所有其他请求后才发送 ack，在最后一条数据处理完后，切换为 LAST_ACK
>
> 如果等待处理完再 ack，那客户端的第一次挥手包可能会超时，触发超时重传，浪费网络资源

**客户端四次挥手后，为什么要等待 2MSL（Maximum Segment Lifetime，报文最大生存时间）？**

> 服务端返回到客户端的报文可能没有处理完，但是端口可能被其他应用占用，会接受到无用的数据包造成数据包混乱。
>
> > - 1 个 MSL，确保四次挥手主动关闭方最后的 ack 报文最终到达对端
> >
> > - 2 个 MSL，确保对端没有收到 ack 重传的报文可以到达

**TCP 状态机：**

- CLOSE
- LISTEN
- SYN_SEND
- ESTABLISHED
- SYN_RCVD

![TCP 状态机](./TCP%20%E7%8A%B6%E6%80%81%E6%9C%BA%E5%8F%98%E5%8C%96.png)

**TCP 鞋带时间戳的作用？**

> 时间戳是存放在 TCP 头部的选项（options）中

- 计算时延
- 防止序列号回绕

**TCP 超时重传时间（STO）怎么计算？**

> 平滑往返时间（Smoothed round trip time，SRTT）

**TCP 如何流量控制？**

- TCP 头部的窗口大小
- 滑动窗口
- 发送端与接收端缓冲区

**TCP 如何 keep-alive？**

> 定时发送 keepalive 探测包，默认：7200s

**TCP 与 UDP 的区别？**

- TCP 是面向连接的可靠的基于字节流的传输协议
- UDP 是无连接的基于数据包的传输协议

> TCP 可靠主要表现在，面向连接，消息有序，消息超时重发，流量控制
> UDP 协议更简单

#### HTTP/HTTPS

### UDP

## 设计模式

### 六大原则

- 单一职责原则。
- 开闭原则。
- 里氏替换原则。
- 依赖倒置原则。
- 接口隔离原则。
- 迪米特法则（最少知道原则）。

### 经典 21 种设计

- 单利模式
- 工厂模式
- 代理模式
- 建造者模式
- 模板方法模式
- 外观模式（门面模式）
- 原型模式
- 策略模式
- 观察者模式
- 。。。
- 装饰器模式

## Java SE

## 集合

### List

- ArrayList
- LinkedList

### Map

- 链表转红黑树阈值：8
- 扩容方法 resize 调用条件：
  - map 初始化。
  - map 中存储的 key-value 数量大于 threshold 。

#### ConsurrentHashMap

- HashTable 使用 synchronized 对全表加锁，锁的粒度大效率低。
- JDK 1.7 使用 segement 数组 + HashEntry 链表数组结构，对 segement 加锁实现同步，相对于 HashTable 降低了锁的粒度。
- JDK 1.8 之后，结构与 HashMap 相同 数组 + 链表/红黑树，对数据的每个 node 用 synchronized 和 CAS 操作，进一步降低了锁的粒度。

### IO

- 阻塞与非阻塞
- 同步与异步

**IO 模型：**

- 阻塞 IO
- 非阻塞 IO
- IO 复用，
  - select 模型
  - epoll 模型
- 信号驱动
- 异步 IO

**零拷贝：**

- 用户态
- 内核态

> 没有优化的情况下，IO 操作要经过 4次拷贝发生 4次上下文切换。
>
> 通过 DMA 硬件支持，CPU 把数据拷贝的工作交给 DMA
>
> kafka 使用零拷贝提高 IO 性能

- mmap
- sendfile

#### BIO 阻塞 IO

#### NIO 非阻塞 IO

**核心组件：**

- Buffer
- Channel
- Selector

### Thread 线程

**线程状态：**

- NEW
- RUNNABLE
- BLOCKED
- WAITING
- TIMED WAITING
- TERMINATE

![线程状态切换](https://img-blog.csdnimg.cn/img_convert/758be9817fc978cb45b1501c949322ff.png)

**线程通信：**

- 锁 + Object.wait()/Object.notify()
- volatile

**线程安全：**

> 可见性，volatile
> 原子性，sychronized
> 有序性，volatile

**死锁：**

> 原因：
>
> > 多线程场景下
> >
> > 1. 互斥条件，一个资源只能被一个线程使用
> > 2. 请求保持，一个线程阻塞后，对已经获得的资源保持不放
> > 3. 不可剥夺，一个进程获取资源后，在未使用完前，不能被剥夺
> > 4. 循环等待，多个线程循环等待资源
> >
> 排查死锁：
> > jstack -l \<PID>
>
> 如何避免：
> > 加锁顺序
> >
> > 减小死锁范围
> >
> > 锁自动释放

#### ThreadLocal

**引用类型：**

- 强引用
- 软饮用
- 弱引用
- 虚引用

**ThreadLocalMap:**

#### 线程池

**配置参数：**

- 核心线程数，核心线程数量
- 最大线程数，最大线程数量
- 存活时间，线程池中非核心线程空闲时间
- 存活时间单位
- 线程工厂，
- 阻塞线程队列，存放任务
- 线程池满淘汰策略，线程池饱淘汰任务策略

**异常处理：**

- 使用线程池的 submit() 返回 FutureTask.get() 抛出异常，try...catch 处理。
- 自定义 ThreadFactory，创建线程时设置 UncaughtExcepthonHandler ，在 uncaughtException() 中处理。
- 重新 ThreadPoolExecutor 的 afterExecute()，任务执行异常可以在此方法中拿到。

**默认实现：**

- newFixedThreadPool
- newCachedThreadPool
- newSingleThreadExecutor
- newScheduleThreadPool

**工作队列：**

- ArrayBlockingQueue
- LinkedBlockingQueue
- DelayQueue
- PriorityBlockingQueue
- SynchronousQueue

**拒绝策略：**

- AbortPolicy，抛出异常，默认
- CallerRunsPolicy，调用线程执行
- DiscardPolicy，丢弃
- DiscardOldestPolicy，丢弃最老

### 并发编程 JUC

#### 锁分类

- 偏向锁，轻量级锁，重量级锁
- 乐观锁，悲观锁
- 公平锁，非公平锁

#### synchronized

- 非公平锁
- 可重入
- 锁升级

**对象内存结构：**

- 对象头
  - Mark word，记录对象的锁信息
- 实例数据
- 附加信息

**原理：**

> 编译器生成 ACC_SYNCHRONIZED 关键字标识锁
>
> 以来操作系统的 monitorenter 和 monitorexist 指令
>
> JDK 1.6 之前是重量级锁，JDK 1.6 之后修改了锁的实现
> >
> > mutex 是操作系统指令，使用时会有用户态和内核态的切换影响性能。
> >
> > JDK 1.6 之后引入了偏向锁和轻量级锁，JVM 层面减少用户态和内核态的切换。
> >
> > 优化了线程竞争资源不激烈的场景。

#### CAS，Compare And Sweep

> CPU 原语操纵，JDK 的 Unsafe 在 JVM 使用 CPU 指令 cmpxchg

**CAS 问题：**

- ABA 问题，通过版本号解决
- 自旋性能浪费

#### JMM（Java 内存模型）

![JMM](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKbkcTibzPYSrl5EiaBvFO80Z437Z9zoWaOlddfByaj0N8NBrVkhicVASCib71f9RzTPCXIECKDWA4pf5A/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

> JVM 屏蔽硬件和操作系统的差异
>
> 线程之间的共享变量存储到主内存中，每个线程都有自己的的本地内存。
> 本地内存存储了线程读/写共享变量的副本。
> 线程对变量操作是对本地内存的副本进行的，不能直接对主内存的变量操作。

- volatile，可见性/禁止指令重排序
  - 内存屏障
- happens-before 规则。

#### AQS

![AQS](https://pica.zhimg.com/80/v2-99ff696984f73f419012e3287c5a5f18_1440w.webp?source=1940ef5c)

- ReentrantLock
- ReentrantReadWriteLock
- CountDownLatch
- Semaphore

#### ReentrantLock 可冲入锁

## JVM

**调优指标：**

- 停顿时间
- 吞吐量
- 垃圾回收频率

**排查工具：**

- jps，查看 Java 进程
- jstat，Java 进程统计信息，常用于查看 GC 情况
- jinfo，Java 进程运行参数
- jmap，Java 进程的内存信息，可用于将内存信息导出为 dump 文件，使用 MAT 工具进行分析
- jstack，用于查看线程信息，排查死锁问题
- ali 的 arthas 开源诊断工具

**JIT 即时编译优化：**

- 方法內联
- 逃逸分析
  - 锁消除
  - 栈上分配
  - 标量替换

**类加载过程：**

- 加载，装载 class 文件到 JVM 的方法区
- 链接，验证 class 文件并初始化类变量为零值
  - 验证，验证 class 文件
  - 准备，赋零值
  - 解析，符号引用转直接引用
- 初始化，类变量初始化为默认值

**类加载器：**

- BootstrapClassloader
- ExtClassloader
- AppClassloader

**双亲委派：**

一种安全机制，保证 JDK 核心类库不被破坏。一个字节码类文件被两个不同的加载器加载是两个不同的类。

如何区分两个类是不同的：

- 类的全限定名
- 类加载器

**打破双亲委派：**

- 自定义 Classloader，重写 loadClass()。
    Tomcat Web容器，运行多个服务端，通过每个应用的类加载器 WebAppClassloader 打破双亲委派机制将 Web 应用隔离开。
    如果加载不到，再委托 ShareClassloader 加载。
    CommonClassloader，CatalinaClassloader
- SPI 机制
    JDBC 的 DriverManager 通过线程获取线程的 contextClassloader ，实际上是 AppClassloader，使用 contextClassloader 对 SPI 引入的 Driver 进行加载。

**JVM 运行时数据区结构：**

> Java 内存模型，与并发相关，屏蔽了计算机底层的细节，在上层调用 api 时不关心底层实现，并且屏蔽了操作系统的差异。
>
> Java 内存结构，运行时数据区，

- 线程共享
  - 堆，垃圾回收
    - 新生代
      - Eden
      - Survivor
        - From
        - To
    - 老年代
    - 常量池
      - 静态
      - 动态
  - 方法区，元空间
    - 类信息
- 线程独享
  - 虚拟机栈
    - 栈帧，每个方法调用创建一个栈帧
      - 操作数栈
      - 局部变量表
      - 方法返回值
      - 动态链接
  - 本地方法栈
  - 程序计数器，记录线程执行的字节码地址

### 垃圾回收

> JVM 垃圾，不再使用的对象。

**怎么确定一个对象是垃圾？**

- 引用计数法
- 可达性分析法
  - GC Roots，向下寻找，可以关联到的对象就是可达。
    - 栈帧局部变量表
    - 方法区
  
**垃圾回收算法：**

- 标记-清除
- 标记-复制
- 标记-整理

**常用的垃圾回收器：**

- 新生代
  - Serial
  - Parallel Scavenge
  - ParNew
- 老年代
  - Serial Old
  - Parallel Old
  - CMS，Concurrent Mark Sweep
    1. 初始标记，STW 扫描年轻代标记老年代被年轻代对象指向的对象
    2. 并发标记，根据 GC Root 标记可达对象。
    3. 并发预处理
    4. 重新标记，STW
    5. 重新标记，STW
    6. 并发清除
    > 空间预留
    > 内存碎片，出发 Full GC，STW，Serial Old
- G1
- ZGC

**垃圾回收类型：**

- Minor GC
- Major GC
- Full GC

## Spring、Spring Boot

## 微服务 Spring Cloud

### 配置中心 Nacos

### 服务注册与发现 Nacos 、Eureka

## Netty

## 分布式

### CAP

- Consistency，一致性
- Availability，可用性
- Partition tolerance，分区容错性

### BASE

- Base Available，基本可用
- Soft state，软状态
- Eventually Consistent，最终一致性

### 分布式事务

- 2PC
- 3PC
- TCC
- MQ 事物消息
- SAGA 长事务

### 分布式算法

#### Paxos

#### Raft

## 数据库

### MySQL

#### 架构

- 连阶层
- 服务层
  - 连接器
  - 查询缓存
  - 分析器
  - 优化器
  - 执行器
- 引擎层
  - InnoDB
  - MyISAM
  - Memery
  - NDB
- 存储层

#### 存储引擎

- Innodb，支持事务，支持外键，聚簇索引，不保存具体行数，支持行锁
  - .frm
  - .ibd
  - .ibdate
- MyISAM，不支持事务，不支持外键，非聚簇索引，保存具体行数，支持表锁
  - .frm，元数据信息，表结构等
  - .MYD，数据
  - .MYI，索引

**面试问题：**

1. MySQL 服务重启后，主键 id 怎么处理？
   > MyISAM 的自增主键存储在文件中，会从服务器关闭前的开始。
   >
   > InnoDB 的自增主键存放在内存中，重启会重新计算，拿到主键最大的。
2. 那个存储引擎的 count(*) 快？
   > MyISAM，因为其表的行数存储在磁盘上。
   >
   > Innodb，不存储行数，需要全表扫描计算。与 InnoDB 的 MVCC 相关，当前行数时不确定的。

#### MySQL 数据类型

- 整数类型
- 浮点类型
- 字符串类型
- 日期类型
- 其他类型

#### 索引

> 索引本质上是：数据结构。
> 索引的目的是为了提高查询效率，降低 IO 成本和排序 CPU 成本。
> 索引本质上也是一种表，会占用硬盘空间和内存空间。虽然提高了查询效率，但是降低了修改的成本。

**索引类型有哪些:**

- 数据类型:
  - B+ 数索引，InnoDB/MyISAM
    - 非叶子结点不存储数据，只存储键值信息。
    - 所有的叶子结点之间都有一个指针。
    - 数据记录存放在叶子结点。
  - Hash 索引，Memery
  - Full-Text 索引，MyISAM/InnoDB
  - R-Tree 索引，MyISAM
- 物理存储:
  - 聚簇索引，**回表问题**
  - 非聚簇索引
- 逻辑角度:
  - 主键索引
  - 普通索引
  - 唯一索引
  - 复合索引
  - 空间索引

**哪些场景需要创建索引：**

- 主键
- 频繁查询的字段
- 关联其他表
- 普通索引/复合索引选择，高并发下建议复合
- 查询排序的字段
- 查询分组的字段

**哪些情况不创建索引：**

- 表记录少
- 经常进行数据更新的表
- 频繁更新的字段不适合
- 数据重复分布均匀的字段
- where 使用不到的字段

**覆盖索引：**

> select 查询时索引直接覆盖了要返回的列，避免回表造成的 IO 消耗。

#### SQL

**count(*) 和 count(1)和count(列名)区别？**

- 执行效果上：
  - count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL
  - count(1)包括了所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL
  - count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。
- 执行效率上：
  - 列名为主键，count(列名)会比count(1)快
  - 列名不为主键，count(1)会比count(列名)快
  - 如果表多个列并且没有主键，则 count(1) 的执行效率优于 count(*)
  - 如果有主键，则 select count（主键）的执行效率是最优的
  - 如果表只有一个字段，则 select count(*) 最优。

#### 事务

**事务的基本要素：**

- A，Atomicity 原子性
- C，Consistency 一致性
- I，Isolation 隔离性
- D，Duration 持久性

**并发处理的问题：**

- 更新丢失
- 幻读（插入/删除），事务多次读取到了其他事务插入的数据
- 脏读，事务读到了其他事务回滚了的数据
- 不可重复度（更新），事务多次读到的数据被其他事务提交更新造成不一致

**事务隔离级别：**

- RU，读未提交
- RC，读已提交
- RR，可重复度，MySQL 默认。
- S，串行化

> MySQL 通过 Next-key 锁避免 RR 幻读出现。

**MVCC 多版本控制：**

#### 锁机制

**锁分类：**

- 对数据操作的类型
  - 读锁，共享锁
  - 写锁，排他锁
- 对数据操作粒度：
  - 表锁
  - 行锁
  - 页锁
  
**InnoDB 锁：**

- 行锁
  - 共享锁（S）
  - 排他锁（X）
- 表意向锁（Intention locks），
  - 意向共享锁（IS），事务在给行加共享锁前必须要先获取表的意向共享锁
  - 意向排他锁（IX），事务在给行加排他锁前必须要先获取表的意向排他锁

**InnoDB 行锁算法：**

- 记录锁
- 间隙锁
- 临键锁，记录锁和间隙锁的组合，主要目的是解决幻读

**select for update ？**

> 仅适用于 InnoDB，仅在事物内部有效。
>
> 执行时，会为查询结果加排它锁，其他线程的更新和删除会被阻塞。
>
> 只有通过索引检索才会加行级锁，否则使用表锁。

**M有ISAM 锁：**

- 表级共享锁
- 表级排他锁

**Inn哦DB 避免死锁：**

- 并发写入时，提前获取必要的锁资源。
- 如果要对多个表进行加锁，需要通过相同的顺序。
- 修改隔离级别

#### MySQL 调优

**explain 执行计划：**

- id
- select_type
  - SIMPLE，简答单表查询
  - PRIMARY，主表
  - SUBQUERY，select 或 where 中的子查询
  - DERIVED，from 中的子查询
  - UNION
  - UNION RESULT，从 UNION 的结果表中 select
- table，表名
- type
  - system，只有一行记录
  - const，通过逐渐索引和唯一索引一次找到
  - eq_ref，唯一索引
  - ref，非唯一索引
  - fulltext
  - ref_or_null
  - index_merge
  - unique_subquery
  - range，范围
  - index，全索引扫描
  - ALL，全表扫描
- possible_keys，可能使用的索引
- key，使用的索引，如果为 NULL 表示没有用到索引
- key_len，索引长度
- ref，
- rows，预估遍历的行数
- extra，附加信息
  - using filesort
  - using temporary，使用临时表保存中间结果
  - using index，表示使用了覆盖索引
  - using where，使用了 where 过滤
  - using join buffer，使用了连接缓存
  - impossible where，where 子句返回 false，查询不到数据
  - select table optimized away，
  - distinct，优化 distinct 操作

**慢查询：**

- 开启
  - 临时开启，设置全局变量
  
    ```shell
    mysql> set global slow_query_log='ON';
    mysql> set global slow_query_log_file='/var/lib/mysql/hostname-slow.log';
    mysql> set global long_query_time=2;
    ```

  - 永久开启，配置文件中开启

    ```text
    [mysqld]
    # 开启慢查询统计
    slow_query_log = ON
    # 慢查询存放位置
    slow_query_log_file = /var/lib/mysql/hostname-slow.log
    # 慢查询时间
    long_query_time = 3
    ```

**性能优化：**

- 索引优化
  - 全职匹配
  - 最左原则
  - 不操作索引，否则索引失效
  - 索引无法使用范围条件右边的列
  - 使用覆盖索引
  - is null，is not null 无法使用索引
  - like 最左匹配原则
  - 少用 or
  - <>，not in，!= 无法使用索引，使用 >，<，><=，between and，in 可能命中索引
  - 避免字段类型或编码类型转换
  - 8+ 版本中，新增了**索引跳跃扫描**，可能会不符合索引最左匹配原则
- 查询优化
  - 小表驱动大表
  - order by
    - 尽量使用 index 排序，避免 filesort
    - 尽量在索引键完成排序
    - where 子句与 order by 子句条件排列符合索引最左原则
    - 遵守最左原则
    - 增大 sort_buffer_size，max_length_for_sort_data 参数配置
    - where 高于 having，尽量把条件放到 where 中
- 数据类型优化
  - 索引使用长度小的类型，可以减小 io 和 cpu 使用
  - 尽量避免 null
- 子查询优化：
  - 适用表连接替换 in
  - 适用复合索引，避免回表
  - 复核所以要以来最左原则
  - 在 8+ 版本中，会对子查询进行物化，性能接近表关联

#### 分区、分库、分表

#### 主从复制

### Redis

#### Redis 数据类型

- 基础类型
  - String
  - List
  - Set
  - SortedSet
  - Hash
- 其他
  - HyperLogLog
  - Geo
  - Pub/Sub

**keys 遍历问题：**

> Redis 的数据操作事单线程的。
> keys 指令执行时会阻塞，其他线程无法执行造成卡顿。
> 可以是用 scan 代替，可能会出现重复的 key ，需要查询客户端去重

**使用 Redis 实现队列：**

> 数据结构 List 支持 rpush 和 lpop 指令，
> lpop 需要自悬，可以使用 blpop 阻塞获取消息。
>
> 使用 pub/sub 订阅模式实现 1:N 的消息队列，
> 缺点是生产者下线会丢失消息。
>
> 延时消息队列，使用 SortedSet 把时间戳作为 score，
> 使用 zrangebyscore 指令获取。

**Redis 的持久化：**

- RDB，非实时，镜像全量持久化，停机可能会造成数据丢失。
- AOF，实时，增量持久化。

> 需要 RDB 与 AOF 配合使用，
> RDB 恢复数据后，再将 AOF 最近的记录重放
>
> 突然掉电的情况下，AOF 也可能会造成数据丢失，可以在每次写指令后 sync，
> 但是高并发情况下影响性能不现实，可以设置 sync 间隔时间短一点，只丢失很短时间内的数据。

**分布式锁：**

setnx + expire

**缓存问题：**

- 缓存穿透，用户查询的数据缓存和数据库中都没有数据，造成每次都是无效的数据库查询。
  - 接口查询参数校验
  - 请求 key 赋值为 null，并设置一个较短的过期时间。
  - 布隆过滤器
- 缓存击穿，热点 key 过期，造成请求直接打到数据库。
  - 查询数据时增加互斥锁。
- 缓存雪崩，大量 key 过期，请求直接打到后台数据库中，造成数据库崩溃。
  - key 的过期时间随机，不要同时过期

**内存淘汰机制：**

> 缓存满时，会触发 Redis 的内存淘汰机制。
>
> 过期策略：定期删除和惰性删除

- noeviction，返回错误
- allkeys-lru，回收最少使用的
- volatile-lru，回收过期集合中最少使用的
- allkeys-random，随机
- volatile-random，过期集合中随机
- volatile-ttl，回收过期集合并 ttl 最小的

**Redis 主从同步机制：**

> 首次同步时，bgsave 命令生成 RDB ，并将后续的写操作写到内存 buffer 中，将 RDB 复制到从节点
>
> 从节点将 RDB 加载到内存，再通知主节点将同步期间的操作记录同步。
>
> 后续数据同步通过 AOF 同步。

#### Redis 集群

- Redis Sentinal，高可用，主从，哨兵节点负责选举主节点保证结群的高可用
  - 哨兵的作用
    - 集群监控
    - 消息通知
    - 故障转移
    - 配置中心
- Redis Cluster，高扩展，分片

### Mongodb

## 中间件

### 消息队列

**什么是消息中间件：**

> 

**消息中间件作用：**

- 解耦
- 削峰
- 异步通信
- 缓冲
- 冗余
- 扩展性
- 可恢复性

**消息中间件使用场景：**

- 异步通信
- 消息存储处理

**消息中间件如何选型：**

- 支持语言
- 通信协议
- HA 高可用
- 数据可靠性
- 性能
- 事务支持
- 消息推拉模式
- 开发与运维难度
- 生态

#### kafka

**架构，有哪些角色：**

![架构图](https://img.bosszhipin.com/beijin/cms/e39f6f34ff4f63432ad863dcc3bc37c4.png)

- Producer
- Broker
- Topic，消息划分逻辑单位
- Partition，一个 Topic 可以划分为多个分区，多个分区支持并发读写，一个分区只能属于一个 Topic，是一个追加写的日志文件
- Offset，消息在分区上的唯一标识，保证消息的顺序性，不可以跨区，因此 Kafka 只能保证分区消息有效
- Record，写入的可以被读取的消息记录，key-value-timestamp
- Replication，Kafka 保证高可用的的方式，同一 Partition 在多个 Broker 上有副本，主副本对外提供读写操作，主副本出现问题 Controller 从其他副本重新选举新的主副本。
- Consumer
- Consumer Group，消费者分组，一个消费者组可以包含一个或多个消费者，分组内消费者消费消息不重复，不同分组的消费者互不影响，通过消费者组实现了消息的 P2P 模式和广播模式。

**Zookeeper 的作用：**

> 集群管理、元数据管理

- Broker 注册
- Topic 注册
- 生产者负载均衡
- 消费者负载均衡

**Producer 生产消息：**

![消息发送](https://img.bosszhipin.com/beijin/cms/974433f69c44433ca8ff4a65a6347f37.png)

**Kafka 如何保证数据的高可用？**

- 副本
- ack
- HW

**分区数是否可以减少？**

> 不可以，否则会造成数据丢失。

**Kafka 是否支持事务？**

0.11 后续版本支持，实现 exactly once 语义

> 三种语义：
>
> 1. at most once，至多一次
>
> 2. exactly once，精确一次
>
> 3. at least once，至少一次

**Kafka Producer 执行过程：**

**Kafka Producer 参数：**

- boootstrap.server，Broker 地址
- key.serializer，key 序列化
- value.serilizer，value 序列化
- batch.num.messages，每次批量消息数量，默认：200
- **request.required.acks**，producer 为 async 时起作用，需要权衡消息丢失和发送效率
  - 0，默认，无需等待 leader 确认
  - 1，需要 leader 确认写入本地 log 并立即确认
  - -1，所有备份都完成后确认
- request.timeout.ms，超时时间，默认 10000
- partitioner.class
  - kafka.producer.DefaultPartitioner，默认，更具 key 提供分区策略，顺序处理时可以自定义策略保证相同类型的数据分配到一个分区。
- producer.type，消息发送时同步还是异步
  - async，默认，异步，kafka.producer.AsyncProducer
  - sync，同步，kafka.producer.SyncProducer
- compression.type，消息压缩，可降低网络 IO
  - none，默认，不压缩
  - gzip
  - snappy
  - lz4
- compression.topics，制定需要压缩的主题，默认：null
- message.send.max.retries，消息发送重试次数，默认：3
- retry.backoff.ms，每次尝试增加的额外间隔时间，默认：300
- topic.metadata.refresh.interval.ms，定期获取元数据的时间，分区丢失 leader 不可用会主动获取，
  - 如果为 0 表示每次发送都获取，
  - 如果是负值表示只有失败时获取，
  - 其他，默认：600000
- queue.buffering.max.message，缓存消息的最大数量，async 时起作用，
- queue.enqueue.timeout.ms，
  - 0，queue 满丢弃
  - 负值，满阻塞，默认，-1
  - 正值，满阻塞时间

**Kafka consumer 执行顺序：**

**Kafka consumer 参数：**

- bootstrap.server
- group.id，消费者组
- key.deserializer
- value.deserializer
- session.timeout.ms，coordinator 检测失败时间，Consumer Group 主动检测崩溃的时间间隔，默认：10s
- auto.offset.reset，消费者长时间失效导致 offset 失效，
  - 默认：latest
  - erliest
- **enable.auto.commint**，是否主动提交位移
  - false，手动提交，exactly once 最好使用手动提交
  - true，自动提交，
- fetch.max.bytes，单次拉取的最大字节数
- max.poll.records，单次拉取的最大消息数，默认：500
- request.timeout.ms

**Kafka Rebalance：**

**如何保持消息顺序消费？**

**消息积压如何处理？**

#### RocketMQ

#### RabbitMQ

### Zookeeper

## 容器化

### Docker

### k8s
